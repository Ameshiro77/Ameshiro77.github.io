---
uuid: 18bde170-9ab5-11ef-944c-674999675c10
title: 论文阅读-6G下的分布式训练：通信与计算角度
author: Ameshiro
top: false
cover: 'https://s2.loli.net/2023/04/03/pvexKZFJ94oGbu8.jpg'
toc: true
mathjax: true
copyright_author: Ameshiro
hidden: false
tags:
  - 论文阅读
  - 分布式训练
categories:
  - AI无线通信
abbrlink: 49b27560
date: 2024-11-02 22:00:06
updated:
description:
img:
top_img:
password:
summary:
copyright:
copyright_author_href:
copyright_url:
copyright_info:
aplayer:
highlight_shrink:
aside:
---

​		IEEE WC,JCR-Q1,IF10.9,2023年。论文标题：Distributed Learning Meets 6G: A Communication and Computing Perspective

# 摘要

​		随着移动设备的计算能力、存储容量不断增长，在6G蜂窝网络下有许多研究面向分布式训练（DL）。结合边缘计算，联邦学习FL可以成为无线网络中的DL**架构**。本文呢主要介绍了通常的分布式学习和基于FL的策略是如何用于6G中，并且取得通信与计算上的平衡。作为一个实践案例，本文将FL框架下的MARL用在了dynamic spectrum access（DSA）问题上。

# 6G下的分布式训练

​		以蜂窝网络为例：由于蜂窝无线网络具有分布广泛且偶尔稀疏的特性，并且包含可能存在异构性的终端设备，因此**分布式学习（DL）**的范式在 "将机器学习方法应用于无线网络问题" 中变得至关重要。主要原因在于：

​		1.随着移动设备、IoT设备计算能力和存储空间越来越强，可以生成指数级多的用户本地数据和环境感知数据；2.由于把大量数据从终端经过限宽的信道传到服务器节点有所限制，且加之用户数据隐私性的问题，在每一轮训练中把本地数据传到服务器聚合不是最优的。

​		因此，终端设备就最好生成本地数据存储好，然后仅仅传递本地训练得到的模型参数给中央服务器，再去更新一个全局模型。**FL就是这种架构的变体之一，构成了无线通信系统中分布式机器学习研究的绝大部分**。

​		FL特别适用于蜂窝系统这样的大规模无线网络。特别是FL解决了隐私问题（许多传统DL架构共享数据），只传参数的方式也**减小了通信开销**。

## FL应用于DSA

​	传统集中式训练数据量大、计算时间长且通信开销大，边缘计算支持的联邦学习可以成为一种有效方法。联邦学习不同于其他DL的因素在于：1.收集到的数据不一定时iid的；2.不同联邦学习参与者的本地数据集在规模、分布上可能差异显著（比如手机pk车辆，城市用户手机地图pk乡村的）；3.FL的边缘服务器之间的无线连接可能不够可靠。	

​	本文将DSA作为FL可应用的一个特殊场景。频谱管理机制有静态和动态两种，动态频谱接入中，有两种用户：授权用户即主用户PUs；和无授权用户即次用户SUs。DSA分别为两种用户提供有/无质量保证的服务，可以在无需为SUs添加新频谱资源的情况下，优化频谱资源利用。本文应用MARL驱动的FL于DSA，图示为：

![image](https://raw.githubusercontent.com/Ameshiro77/BlogPicture/main/pic/image-20241128175253704.png)

​	

​	假设有N个SU和M个信道（N>M），每个SU在特定时间只能访问一个信道。为避免SU干扰，SU不能在PU占用的信道上进行传输。SU之间可能会产生干扰，本文为SU应用了上述频谱接入框架。

​	训练时：一个初始化的策略网络首先被分配给所有智能体。在每个通信周期中，智能体清空其缓冲区，观察环境，依据其策略采取行动并从环境中获得奖励。经过足够多的迭代，每个智能体学习到一个更新后的本地模型。然后，这些更新后的本地模型被共享并在中央服务器上进行聚合以更新全局模型。由于选择合适数量的用户参与每个通信周期对加速收敛至关重要在FL算法的每一轮聚合中，考虑执行部分用户参与（假设每个用户在特定训练轮次中被选中的概率是均匀的）。

​	**仿真。**仿真设置中了8对基站-用户设备（BS-UE）随机分布在400m x 6400m的区域中，配置了四个不同的频段作为可用通信信道。仅考虑下行通信，即从8个基站（BS）到其各自用户设备（UE）的传输。这8个BS充当次用户（SU）发送端（SU Tx），8个UE充当SU接收端（SU Rx）。设定每个信道被主用户（PU）占用的概率为20%。在每个时间步t中，策略将智能体的观测映射到其动作（0~4，表示不访问信道/选哪个信道），之后获得奖励。观测包括到前一个时间步的历史吞吐量均值和前一时间步在所有信道上的吞吐量。

​	本文实验是和传统DL相比的。传统DL里，每个SU Tx从中央服务器接受模型后就自己干自己的了；而FL框架下间接实现了SU Tx之间的协作。

<img src="https://cdn.jsdelivr.net/gh/Ameshiro77/BlogPicture/pic/image-20241105163710983.png" alt="image-20241105163710983" style="zoom:67%;" />





