---
uuid: c4a07eb0-a0fc-11ef-9f6f-2de627acb94f
title: 论文阅读-IoT中基于多源异构设备的联邦生成式模型
author: Ameshiro
top: false
cover: 'https://s2.loli.net/2023/04/03/pvexKZFJ94oGbu8.jpg'
toc: true
mathjax: true
copyright_author: Ameshiro
hidden: false
date: 2024-11-12 21:48:16
updated:
description:
img:
top_img:
password:
summary:
tags:
categories:
copyright:
copyright_author_href:
copyright_url:
copyright_info:
aplayer:
highlight_shrink:
aside:
---

[Federated Generative Model on Multi-Source Heterogeneous Data in IoT | Proceedings of the AAAI Conference on Artificial Intelligence](https://ojs.aaai.org/index.php/AAAI/article/view/26252)，2023年

# 摘要

​		现有的大多数工作都是集中实现生成式模型，引起安全性、隐私的问题并带来超额通信开销。少数工作考虑了当训练数据来自各异构设备时的分布式生成模型。本文中，为了解决这一问题，设计了一种联邦生成模型框架，可以在层级的IoT系统中学习到一个强大的生成器，可以在两种场多源异构数据场景中使用：特征相关的场景（特征形状类似）和标签相关的场景。此外，本文设计了一种同步和异步更新的方法来满足不同的应用需求。实验在一个模拟数据集和多个现实数据集上执行。

# 简介

​	生成模型带来的突破已迅速对多个领域产生了革命性影响，并在物联网（IoT）中的各类实际应用中广泛应用。在物联网环境中，各种设备相互连接，用于生成、收集、共享和处理异构数据，以推动数据驱动型应用的发展。

​	然而，目前大部分研究工作实现的是集中式生成模型，这些模型先将物联网设备的数据收集到中央服务器，再进行训练以达到生成目标。这种集中式生成模型可能容易受到单点故障和隐私泄露问题的影响。此外，用户因隐私顾虑而不愿意与中央服务器共享数据，从而增加了数据收集的难度，阻碍了物联网应用的进一步发展。另一方面，将如此庞大的数据传输到中央服务器也会给物联网带来高昂的通信成本。为了解决隐私和通信成本问题，设计分布式生成模型将是更优的解决方案。且：**在多个物联网设备上数据集是非独立同分布（non-i.i.d.）的情况下，分布式生成模型可以学习混合分布，生成更加多样化的数据**。

​	目前，只有少数研究了分布式生成模型，但在实际物联网场景中忽视了以下关键问题：1.大多数现有工作采用联邦学习模式，需要上传大量模型参数，给有限的网络资源带来负担；2.所有现有研究主要关注独立同分布的数据进行模型训练，而未涉及非独立同分布数据情境；3.没有研究考虑不同物联网设备之间的数据域异质性。

​	本文设计了一个新颖的分布式生成模型框架，考虑了物联网设备的基本特性，包括广泛的地理分布、较低的计算能力、非独立同分布数据及异构数据域。基于不同应用场景下物联网设备中的数据分布及相关性，本文研究了分布式数据生成问题的两种情境：(i) 特征相关情境，即不同群体的数据具有相同的特征但标签不同；(ii) 标签相关情境，即不同群体的数据具有相同的标签但特征不同。

本文的主要贡献如下：

1.基于物联网应用的特性，我们设计了一个三层分层框架来部署联邦生成模型，这是首个考虑多源异构数据的分布式数据生成框架。

2.针对物联网应用中的数据情境，我们在所提出的分层框架下，提出了两种生成模型用于多源数据生成。

3.我们设计了同步和异步更新策略，以便根据不同的应用需求在边缘设备上训练生成器。

4.我们在来自多个数据域的不同数据集上进行了大量实验，对比现有方法，展示了所提数据生成模型的性能。

# 相关工作：关于多源GANs

生成对抗网络（GANs）最初专注于单一数据集上的数据生成。在多源数据场景中，通过提供两个或多个数据源来训练GAN的变体，主要研究条件生成和联合生成。条件生成方法旨在学习在给定其他数据源作为附加信息的条件下，一个数据源的条件分布。不同地，联合生成方法试图学习多个数据源的联合分布，通过在邻域间交换信息来适应全局分布。一些研究简化了此前的结构，将多个生成器改为一个并保留多个判别器的训练结构，这种改进通过聚合判别器的损失反馈到生成器，从而提升生成质量。在此方向上，也有研究考虑了多数据集的分布式数据生成，在该方法中，多个判别器根据其损失值进行加权平均。

自联邦学习范式提出以来，已被用于开发各种GANs，这些方法的细微差别在于是否聚合生成器、判别器或两者。然而，对于这些生成模型来说，高通信成本源于反复传输模型参数。为规避这一问题，另一些改进方法提出设置一个中央生成器并使用本地判别器的损失值来更新生成器，与传输整个模型相比，服务器与本地客户端之间的数据传输量大大减少。然而，这些方案并未专门针对非独立同分布（non-i.i.d）数据，缺乏在实际应用中的扎实基础。上述方法适用于单一数据源，但在多源异构数据源上则不适用。此外，现有针对多源数据的生成模型采用集中模式，限制了它们在分布式数据孤岛中的适用性。

在分布式环境中的生成模型方面，生成对抗并行化是最早将GANs应用于分布式环境的工作，其中每个GAN模型在分布式数据集上进行训练。类似的思想被应用于Gossip GAN中，但在该模型中生成器和判别器。

# 系统框架

​	本文的联邦生成模型框架为一个三层架构，底层是IoT设备，中间是边缘服务器，顶层是一个云服务器。特别地，每个边缘服务器都位于覆盖本地区域的基站下，与覆盖的物联网设备构成一个local community。系统图：

![系统图](https://cdn.jsdelivr.net/gh/Ameshiro77/BlogPicture/pic/image-20241113114105077.png)

​		为了数据生成，每个IoT设备上部署一个discriminator，每个边缘服务器上部署一个community generator，在云服务器上部署一个global generator。定义K是区域数量，$J_k$是第k个区域内的判别器集合，$D_{kj}$是第k个区域的第j个IoT的判别器。

​	训练过程分两阶段：1.本地区域训练，在边缘服务器更新$G_k$; 2.在云服务器的G上全局聚合。在本地训练中，IoT设备和边缘服务器上的G训练捕获异构数据分布；在全局聚合中，本地训练结果发送到云端获得全局数据分布。全局聚合迭代$I_{gl}$次，其中每一次里局部训练迭代$I_{lo}$次。由于近距离的位置分布，一个本地区域的数据通常由相同的特征或标签。

# 特征相关数据生成

​		这一场景中，来自不同区域的数据特征相同而标签不同。如上图所示，三个区域的特征都是0~1像素值的灰度图，但标签分别是digit和cloth。类似的场景还有：不同医院涵盖不同疾病类别；不同位置的传感器可以感知不同空气质量指数，等等。

## 生成器

​		首先是，本地生成器$G_k$会根据从高斯分布里采样的两个向量$z_d,z_g$生成两批数据：$G_k(z_d)$用来更新$D_{kj}$，$G_k(z_g)$用来计算$\mathcal{L}_{D_{jk}}$以反向传播。 类似于softmax，全局聚合通过下式进行：
$$
G=\sum_{k\in\mathbb{K}}\frac{\exp(\mathcal{L}_{D_*}(G_k))}{\sum_{k'\in\mathbb{K}}\exp(\mathcal{L}_{D_*}(G_k))}G_k
$$
​		其中$\mathcal{L}_{D_*}$可以通过同步或异步更新的方式计算，在下述介绍。

## 判别器

​		在本地区域每次迭代训练中，判别器$D_{kj}$进行两步操作：更新和损失函数计算。在第一步，判别器通过IoT设备真实的本地数据x（服从$p_{kj}$分布）和上述产生的假数据进行训练，即优化：
$$
\begin{aligned}\max_{D_{kj}}\mathcal{L}(D_{kj})=&\mathbb{E}_{x\sim p_{kj}(x)}[\log D_{kj}(x)]+\\&\mathbb{E}_{z_{d}\sim p_{z}(z)}[\log(1-D_{kj}(G_{k}(z_{d})))].\end{aligned}
$$
​		在判别器更新后，在用上述的另一个假数据区计算损失函数：$\mathcal{L}_{D_{kj}}(G_k)=\mathbb{E}_{z_d\sim p_z(z)}[\log(1-D_{kj}(G_k(z_g)))]$。之后，损失值送回$G_k$，以计算梯度并更新之。

## 更新策略

​		考虑到IoT设备的多样性和不同应用的需求，更新$G_k$时同步或异步方法在训练过程中被采用。

### 同步更新
