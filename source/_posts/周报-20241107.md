---
uuid: 068c6c30-9ce3-11ef-8e1a-0fa0a8c325e7
title: 周报-20241107
author: Ameshiro
top: false
cover: 'https://s2.loli.net/2023/04/03/pvexKZFJ94oGbu8.jpg'
toc: true
mathjax: true
copyright_author: Ameshiro
hidden: true
abbrlink: af40221c
date: 2024-11-07 16:33:55
updated:
description:
img:
top_img:
password:
summary:
tags:
categories:
copyright:
copyright_author_href:
copyright_url:
copyright_info:
aplayer:
highlight_shrink:
aside:
---

​	主题是6G+分布式训练。首先是找的时候找到了一份白皮书：https://www.6g-ana.com/upload/file/20231214/6383817257425658559789267.pdf；，其中对于分布式学习方法做了以下分类：

![image](https://cdn.jsdelivr.net/gh/Ameshiro77/BlogPicture/pic/image-20241107165627465.png)

​			其中：

![image](https://cdn.jsdelivr.net/gh/Ameshiro77/BlogPicture/pic/image-20241107165854153.png)

​		也就是说，现在许多工作考虑的是，分布式的这些边缘设备收集数据，然后进行分布式训练。在搜索6G+wireless+distributed learning的时候，也确实许多文章虽然标题没有明确写，但是点进去摘要都是在说federated learning。关于联邦学习，也已经说过些许文章；

​		但是在我们最初设想的场景中，比如说一个BS在训练一个DNN，可能在这种背景下，数据集都是由BS管理的。在这种情况下，先不考虑通信开销，还有一个需要考虑的点就是：如果要把数据连带模型发配给边缘节点，肯定会有privacy的问题。为此，在调研中也是发现了一种结合了联邦学习FL和拆分学习SL的方式：[论文阅读-SplitFed：联邦学习+分裂学习 | 雨白的博客小屋](https://www.ameshiro77.cn/posts/86170f50.html)。

​		这种学习方式下，如果我们翻转一下，让数据集集中归BS所有且保证隐私，则可以如下：

​		首先，以MNIST数据集为例，就用一个很简单的DNN去训练学习，然后服务器部署前半模型（和后半模型），客户端部署后半模型。给定一个batch的数据，训练流程：

​		1.BS先经过前半模型，得到中间的smashed data输出；

​		2.BS将模型加上数据（这里的smashed data经过处理，并不是raw data了；**但是label还是要共享的**）分发给边缘节点；（这里显然有更高的通信开销，且在像FL、SL分布式学习的框架中，都是选择几个节点而不是全选的，即一个决策，像SFL是随机的）

​		3.边缘节点用smashed data在本地前向传播并反向传播计算梯度，得到各自的梯度和参数；

​		4.这些参数、梯度汇总到服务器，做一个平均，更新服务器部署的后半模型，并用梯度反向更新前半模型。

-----

​		以上是一种数据集中式的做法，可能符合我们所讨论的情形，但或许不符合现在主流的场景。**数据集中处理的话，有个好处就是分配给边缘节点的数据一定是同分布的；而依赖局部产生数据的话可能不是iid的。**在搜索6G+SFL中，也确实有些许相关的工作，比如[Accelerating Split Federated Learning Over Wireless Communication Networks | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/document/10304624)这篇文章提出，联合优化分割点选择和带宽分配，来最小化系统延迟（用的一种交替优化的办法，没有用神经网络）。
